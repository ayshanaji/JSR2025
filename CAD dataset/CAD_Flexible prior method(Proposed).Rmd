---
title: "Method2- Overall- Hierarchical"
author: "Ayisha - TRU- T00727585"
date: "2024-11-12"
output: html_document
---


```{r}
# Load necessary libraries
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
library(ISLR)
library(dplyr)
library(tidyr)
library(coda)
library(reshape)
library(stats4)
library(MCMCpack)
library(ggplot2)
library(MASS)
library(Matrix)
library(knitr)
library(readr)
library(mvtnorm)
library(stargazer)
library(pROC)
library(caret)
library(gridExtra)
library(grid)
```


```{r}
# Load data
trainData <- read.csv("training_data_tt.csv", header = TRUE, stringsAsFactors = FALSE)
#validationData <- read.csv("validation_data.csv", header = TRUE, stringsAsFactors = FALSE)
testData <- read.csv("test_data_tt.csv", header = TRUE, stringsAsFactors = FALSE)

# Define logistic log-likelihood function
flogis.log <- function(beta, zlv, X, y) {
  p <- plogis(X %*% (beta * zlv))
  sum(ifelse(y, log(p), log(1 - p)))
}

# Prepare data for analysis, excluding the intercept
y_train <- trainData[, "HeartDisease"]
X_train <- model.matrix(as.formula(paste("HeartDisease ~ .")), data = trainData)  
#y_valid <- validationData[, "HeartDisease"]
#X_valid <- model.matrix(as.formula(paste("HeartDisease ~ .")), data = validationData)
y_test <- testData[, "HeartDisease"]
X_test <- model.matrix(as.formula(paste("HeartDisease ~ . ")), data = testData)

# Update k to reflect the new number of columns without the intercept
k <- ncol(X_train)
n <- nrow(X_train)


```

```{r}
# Step 1: Performing Frequentist Logistic Regression for Initial Beta Estimates
reg.glm <- glm(HeartDisease ~ .  , data = trainData, family = binomial)
BETA_init <- as.vector(reg.glm$coef)
vcov_matrix <- vcov(reg.glm)


# Step 2: Calculating the Prior Mean and Standard Deviation for Beta
pmn.beta <- BETA_init
psd.beta <- vcov_matrix

```


```{r}
# Initial setup for MCMC
S <- 140000  # Number of MCMC iterations
c <- 1       # Proposal variance tuning parameter
k <- ncol(X_train)  # Number of predictors (confirm this matches)
beta <- BETA_init
alpha1 <- 1
alpha2 <- 1
# Initialize zlv based on global theta
global_theta <- rbeta(1, alpha1, alpha2)  # Initial global theta from Beta prior
theta_j <- rbeta(k, global_theta, 1 - global_theta)  # Initialize each theta_j from global theta

zlv <- rbinom(k, 1, theta_j)  # Initial selection/exclusion indicators for predictors

# Initialize matrices and counters
acsb <- acsg <- 0
BETA <- matrix(0, nrow = S, ncol = k)   # Store samples of beta for each iteration
ZLV <- matrix(0, nrow = S, ncol = k)    # Store samples of zlv for each iteration
THETA <- matrix(0, nrow = S, ncol = k)       # Store samples for each theta_j
accept_beta <- rep(0, k)                # Acceptance count for beta updates
accept_zlv <- rep(0, k)                 # Acceptance count for zlv updates
global_theta_values <- numeric(S)                  # Store samples for global theta
short_chain_length<-1000
# Confirm dimensions
print(dim(X_train))  # Should match (n, k)
print(length(beta))  # Should match k
print(length(zlv))   # Should match k
print(dim(vcov_matrix)) 
# Proposal Variance for MCMC
var.prop <- c * vcov_matrix  


```



```{r}
# Track acceptance rate
set.seed(1)  # For reproducibility

for (i in 1:10) {  # Adjust the proposal variance over 10 iterations of tuning
  acs <- 0  # Acceptance count
  
  for (s in 1:short_chain_length) {
    # Propose a new beta using current variance scale (c * vcov_matrix)
    beta.p <- t(rmvnorm(1, beta, c * vcov_matrix))
    
    # Calculate log acceptance ratio (log-hastings ratio)
    lhr <- flogis.log(beta.p, zlv, X_train, y_train) - flogis.log(beta, zlv, X_train, y_train) +
           dmvnorm(t(beta.p), BETA_init, vcov_matrix, log = TRUE) -
           dmvnorm(t(beta), BETA_init, vcov_matrix, log = TRUE)
    
    # Accept or reject based on acceptance ratio
    if (log(runif(1)) < lhr) {
      beta <- beta.p
      acs <- acs + 1
    }
  }
  
  # Calculate acceptance rate
  acceptance_rate <- acs / short_chain_length
  print(paste("Iteration", i, "- Acceptance rate:", acceptance_rate))
  
  # Adjust `c` based on acceptance rate
  if (acceptance_rate < 0.2) {
    c <- c / 2  # Reduce `c` if acceptance rate is too low
  } else if (acceptance_rate > 0.5) {
    c <- c * 2  # Increase `c` if acceptance rate is too high
  }
  
  # Print adjusted `c` value for tracking
  print(paste("Adjusted proposal variance scaling factor (c):", c))
}

# After tuning, `c` can be used in the main MCMC chain
print(paste("Final proposal variance scaling factor (c):", c))
```


```{r}
# Initial setup for MCMC
S <- 140000  # Number of MCMC iterations      
k <- ncol(X_train)  # Number of predictors (confirm this matches)
beta <- BETA_init  # Initial beta coefficients from frequentist logistic regression
alpha1 <- 1
alpha2 <- 1

# Initialize global theta and individual theta_j
global_theta <- rbeta(1, alpha1, alpha2)  # Global sparsity parameter
theta_j <- rbeta(k, global_theta, 1 - global_theta)  # Individual selection probabilities

# Initialize zlv (latent variable for predictor selection/exclusion)
zlv <- rbinom(k, 1, theta_j)  # Initial selection indicators

# Initialize matrices and counters for MCMC sampling
BETA <- matrix(0, nrow = S, ncol = k)   # Store samples of beta
ZLV <- matrix(0, nrow = S, ncol = k)    # Store samples of zlv
THETA <- matrix(0, nrow = S, ncol = k)  # Store samples of theta_j
GLOBAL_THETA <- numeric(S)              # Store samples of global theta
acsb <- acsg <- accept_global_theta <- 0  # Acceptance counters

# Proposal variance for beta updates
var.prop <- c * vcov_matrix  # Covariance matrix from frequentist regression

# MCMC loop
for (s in 1:S) {
  
  # Step 1: Metropolis-Hastings update for beta
  beta.p <- t(rmvnorm(1, beta, var.prop))  # Propose new beta
  lhr <- flogis.log(beta.p, zlv, X_train, y_train) - flogis.log(beta, zlv, X_train, y_train) +
         dmvnorm(t(beta.p), BETA_init, vcov_matrix, log = TRUE) -
         dmvnorm(t(beta), BETA_init, vcov_matrix, log = TRUE)
  
  if (log(runif(1)) < lhr) {
    beta <- beta.p
    acsb <- acsb + 1
  }
  BETA[s, ] <- beta
  
  # Step 2: Metropolis-Hastings update for each component of zlv
  for (j in 1:k) {
    zlv.p <- zlv
    zlv.p[j] <- 1 - zlv.p[j]  # Flip the j-th component
    
    lhg <- flogis.log(beta, zlv.p, X_train, y_train) - flogis.log(beta, zlv, X_train, y_train) +
           sum(dbinom(zlv.p[j], size = 1, prob = theta_j[j], log = TRUE)) - 
           sum(dbinom(zlv[j], size = 1, prob = theta_j[j], log = TRUE))
    
    if (log(runif(1)) < lhg) {
      zlv[j] <- zlv.p[j]
      acsg <- acsg + 1
    }
  }
  ZLV[s, ] <- zlv
  # Step 3: Gibbs update for each theta_j from Beta(global_theta, 1 - global_theta)
for (j in 1:k) {
  repeat {  # Use a loop to ensure theta_j is not exactly 0 or 1
    theta_j[j] <- rbeta(1, global_theta + zlv[j], (1 - global_theta) + (1 - zlv[j]))
    if (theta_j[j] > 0 && theta_j[j] < 1) break  # Exit the loop if valid
  }
}
THETA[s, ] <- theta_j

# Step 4: Metropolis-Hastings update for global theta
proposed_global_theta <- rbeta(1, alpha1 + sum(zlv), alpha2 + k - sum(zlv))  # Propose new global theta

# Calculate log acceptance ratio for global theta
current_likelihood <- sum(dbeta(theta_j, global_theta, 1 - global_theta, log = TRUE))
proposed_likelihood <- sum(dbeta(theta_j, proposed_global_theta, 1 - proposed_global_theta, log = TRUE))
lhr_theta <- proposed_likelihood - current_likelihood + 
             dbeta(proposed_global_theta, alpha1, alpha2, log = TRUE) -
             dbeta(global_theta, alpha1, alpha2, log = TRUE)

if (log(runif(1)) < lhr_theta) {
  global_theta <- proposed_global_theta
  accept_global_theta <- accept_global_theta + 1
}

    GLOBAL_THETA[s] <- global_theta
  
  # Debug output every 1000 iterations
  if (s %% 1000 == 0) {
    cat("Iteration:", s, "- Global theta:", global_theta, "- beta[1]:", beta[1], "- zlv:", zlv, "\n")
  }
}

# Display acceptance rates after MCMC loop
cat("Acceptance rate for beta updates:", acsb / S, "\n")
cat("Acceptance rate for zlv updates:", acsg / (S * k), "\n")
cat("Acceptance rate for global theta updates:", accept_global_theta / S, "\n")

```

```{r}
# Save the results
save(BETA, ZLV,THETA,GLOBAL_THETA,theta_j, file = "OAM2_results_FIMS.RData")

# To load the results back in future sessions
load("OAM2_results_FIMS.RData")

```

```{r}

# Debugging outputs
print(global_theta)
print(proposed_global_theta)
print(current_likelihood)
print(proposed_likelihood)

```


```{r}
theta_samples <- GLOBAL_THETA

plot(theta_samples, type = "l", main = expression("Trace Plot of " * theta), xlab = "Iteration", ylab = expression(theta))

```


```{r}
# Trace plot for global sparsity parameter θ
plot(GLOBAL_THETA, type = "l",
     main = expression("Trace Plot of Global " * theta),
     xlab = "Iteration", ylab = expression(theta))

# Density plot
plot(density(GLOBAL_THETA), main = expression("Density of Global " * theta))

```

```{r}
png("trace_global_theta_CAD.png", width = 800, height = 600)
plot(GLOBAL_THETA, type = "l",
     main = expression("Trace Plot of Global " * theta),
     xlab = "Iteration", ylab = expression(theta))
dev.off()

```
```{r}
png("density_global_theta_CAD.png", width = 800, height = 600)
plot(density(GLOBAL_THETA),
     main = expression("Density of Global " * theta),
     xlab = expression(theta), ylab = "Density")
dev.off()

```

```{r}
effectiveSize(GLOBAL_THETA)
acf(GLOBAL_THETA)
png("acf_global_theta_CAD.png", width = 800, height = 600)
acf(GLOBAL_THETA, main = "ACF of GLOBAL_THETA")
dev.off()
```




```{r}
THETA
```

```{r}
# Load necessary libraries
library(coda)
library(gridExtra)
library(ggplot2)

variable_names <- colnames(X_train)
print(paste("Variable Names:", variable_names))

# Ensure we have names for each column in BETA and ZLV
colnames(BETA) <- variable_names
colnames(ZLV) <- variable_names
BETA_ZLV<-BETA *ZLV
colnames(BETA_ZLV) <- variable_names
# 1. Effective Sample Size (ESS) for `BETA` and `ZLV`
ess_beta <- effectiveSize(as.mcmc(BETA))
ess_zlv <- effectiveSize(as.mcmc(ZLV))
ess_beta_zlv <- effectiveSize(as.mcmc(ZLV))

# Display ESS for both in a summary table
ess_summary <- data.frame(
  Parameter = variable_names,
  ESS_Beta = round(ess_beta, 2),
  ESS_ZLV = round(ess_zlv, 2),
  ESS_BETA_ZLV= round(ess_beta_zlv, 2)
)

# Save ESS Summary as a PDF
pdf("ESS_Summary_Beta_ZLV_OA2.pdf", width = 8, height = 5)
grid.table(ess_summary)
dev.off()

# 2. Trace and Density Plots for Both `BETA` and `ZLV`

# Generate Trace and Density Plots for `BETA`
pdf("Beta_Trace_Density_Plots_OA2.pdf", width = 14, height = 10)  # Adjust dimensions
par(mfrow = c(3, 4), mar = c(4, 4, 2, 1))  # 4x4 grid
for (i in 1:ncol(BETA)) {
  plot(BETA[, i], type = "l", main = paste("Trace Plot for Beta", variable_names[i]), 
       xlab = "Iteration", ylab = variable_names[i])
  plot(density(BETA[, i]), main = paste("Density for Beta", variable_names[i]), 
       xlab = variable_names[i], ylab = "Density")
}
dev.off()

# Generate Trace and Density Plots for `BETA_ZLV`
pdf("BETA_ZLV_Trace_Density_Plots_OA2.pdf", width = 14, height = 10)
par(mfrow = c(3, 4), mar = c(4, 4, 2, 1))  # 4x4 grid
for (i in 1:ncol(ZLV)) {
  plot(BETA_ZLV[, i], type = "l", main = paste("Trace Plot for BETA_ZLV", variable_names[i]), 
       xlab = "Iteration", ylab = variable_names[i])
  plot(density(BETA_ZLV[, i]), main = paste("Density for BETA_ZLV", variable_names[i]), 
       xlab = variable_names[i], ylab = "Density")
}
dev.off()
```



```{r}
# Rename selected variables
colnames(X_train)[colnames(X_train) == "MHR"] <- "Max HR"
colnames(X_train)[colnames(X_train) == "RBPS"] <- "Resting BP"
colnames(X_train)[colnames(X_train) == "Chol"] <- "Cholesterol"
colnames(X_train)[colnames(X_train) == "AgeGrp"] <- "Age group"
```



```{r}


# Removing Initial Samples and Applying Thinning
BETA <- BETA[-c(1:20000), ]
ZLV <- ZLV[-c(1:20000), ]

thin_interval <- 60
BETA_thinned <- BETA[seq(1, nrow(BETA), by = thin_interval), ]
ZLV_thinned <- ZLV[seq(1, nrow(ZLV), by = thin_interval), ]

# Combining BETA and ZLV for Plotting
BETA_ZLV_thinned <- BETA_thinned * ZLV_thinned

# Generate Trace, Density, and ACF plots for BETA
pdf("Beta_Trace_Density_ACF_After_Thinning_OA2.pdf", width = 14, height = 10)
par(mfrow = c(3, 4), mar = c(4, 4, 2, 1))
for (i in 1:ncol(BETA_thinned)) {
  plot(BETA_thinned[, i], type = "l", main = paste("Trace Plot for BETA_thinned", variable_names[i]), xlab = "Iteration")
  plot(density(BETA_thinned[, i]), main = paste("Density for BETA_thinned", variable_names[i]), xlab = variable_names[i])
  acf(BETA_thinned[, i], main = paste("ACF for BETA_thinned", variable_names[i]))
}
dev.off()


# Generate Trace, Density, and ACF plots for BETA
pdf("Beta_zlv_Trace_Density_ACF_After_Thinning_OA2.pdf", width = 14, height = 10)
par(mfrow = c(3, 4), mar = c(4, 4, 2, 1))
for (i in 1:ncol(BETA_ZLV_thinned)) {
  plot(BETA_ZLV_thinned[, i], type = "l", main = paste("Trace Plot for BETA_ZLV_thinned", variable_names[i]), xlab = "Iteration")
  plot(density(BETA_ZLV_thinned[, i]), main = paste("Density for BETA_ZLV_thinned", variable_names[i]), xlab = variable_names[i])
  acf(BETA_ZLV_thinned[, i], main = paste("ACF for BETA_ZLV_thinned", variable_names[i]))
}
dev.off()
```


```{r}

# Ensure we have names for each column in BETA and ZLV
colnames(BETA) <- variable_names
colnames(ZLV) <- variable_names

# 1. Effective Sample Size (ESS) for `BETA` and `ZLV`
ess_beta_thinned <- effectiveSize(as.mcmc(BETA_thinned))
ess_zlv_thinned <- effectiveSize(as.mcmc(ZLV_thinned))
ess_beta_zlv_thinned<-effectiveSize(as.mcmc(BETA_ZLV_thinned))
# Display ESS for both in a summary table
ess_summary <- data.frame(
  Parameter = variable_names,
  ESS_Beta_thinned = round(ess_beta, 2),
  ESS_ZLV_thinned = round(ess_zlv, 2),
  ESS_ZLV_thinned = round(ess_beta_zlv,2)
)
print(ess_summary)
# Save ESS Summary as a PDF
pdf("ESS_Summary_Beta_ZLV_OA2.pdf", width = 8, height = 5)
grid.table(ess_summary)
dev.off()

```








```{r}
# Top 5 Models Analysis
ZLV_list <- as.list(as.data.frame(ZLV))
top5_models <- do.call(paste0, ZLV_list) %>% table() %>% sort(decreasing = TRUE) %>% .[1:5]
top5_probabilities <- top5_models / sum(top5_models)

top5_df <- data.frame(
  Model = paste0("Model ", 1:5),
  Probability = round(as.numeric(top5_probabilities), 4),
  Variables = names(top5_probabilities)
)

# Plotting Posterior Probabilities of the Top 5 Models
plot <- ggplot(top5_df, aes(x = Model, y = Probability)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(Probability, 2)), vjust = -0.5) +
  labs(title = "Posterior Probabilities of Top 5 Models-OVERALL- METHOD2", x = "Model", y = "Posterior Probability") +
  theme_minimal()

ggsave("posterior_probabilities_top5_models_OA2.pdf", plot = plot, width = 10, height = 6)

# Creating Table for the Top 5 Models
table_grob <- tableGrob(top5_df)
pdf("top5_models_table_OA2.pdf", width = 8, height = 6)
grid.draw(table_grob)
dev.off()
```



```{r}


# Define the variable names 
variable_names <- colnames(X_train) 

# Assign these names to the columns of BETA_thinned
colnames(BETA_thinned) <- variable_names
colnames(BETA_ZLV_thinned) <- variable_names

# Calculate Mean Beta Values from Thinned MCMC Samples
beta_means <- colMeans(BETA_ZLV_thinned)
names(beta_means) <- variable_names
```


```{r}
# Load Required Libraries
library(ggplot2)
library(gridExtra)

# --- Helper: Calculate Credible Intervals ---
calculate_quantiles <- function(beta_matrix, probs = c(0.025, 0.5, 0.975)) {
  apply(beta_matrix, 2, quantile, probs = probs)
}

# --- Step 1: Prepare Credible Interval Data ---
beta_quantiles <- calculate_quantiles(BETA_ZLV_thinned)
variable_names <- colnames(BETA_ZLV_thinned)
beta_means <- colMeans(BETA_ZLV_thinned)

# Create dataframe
beta_df <- as.data.frame(t(beta_quantiles))
beta_df$Variable <- variable_names
beta_df <- beta_df[, c("Variable", "2.5%", "50%", "97.5%")]

# --- Step 2: Identify Significant Predictors ---
significant_predictors <- variable_names[apply(beta_quantiles, 2, function(x) !(x[1] < 0 & x[3] > 0))]
beta_df$Significance <- ifelse(beta_df$Variable %in% significant_predictors, "Significant", "Not Significant")

# --- Step 3: Compute Posterior selection Probabilities (PIP) ---
pip <- colMeans(ZLV_thinned)
pip_df <- data.frame(Variable = variable_names, PIP = pip)
pip_df$Significance <- ifelse(pip_df$Variable %in% significant_predictors, "Significant", "Not Significant")

# --- Step 4: Combine into Single DataFrame ---
combined_df <- merge(beta_df, pip_df, by = "Variable", suffixes = c("_CI", "_PIP"))
combined_df$Width <- combined_df$`97.5%` - combined_df$`2.5%`
combined_df <- combined_df[, c("Variable", "2.5%", "50%", "97.5%", "Width", "Significance_CI", "PIP", "Significance_PIP")]

# --- Step 5: Remove Intercept ---
combined_df <- combined_df[combined_df$Variable != "(Intercept)", ]
combined_df$Variable <- factor(combined_df$Variable, levels = combined_df$Variable[order(combined_df$PIP)])

# --- Step 6: PIP Plot (no legend, gray fill) ---
p2 <- ggplot(combined_df, aes(x = Variable, y = PIP, fill = Significance_PIP)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_fill_manual(values = c("Significant" = "black", "Not Significant" = "gray")) +
  coord_flip() +
  labs(title = "Posterior selection Probability", x = NULL, y = NULL) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.y = element_blank(),
    axis.text.x = element_text(size = 8),
    legend.position = "none"
  )

# --- Step 7: Credible Interval Plot (gray points + error bars) ---
combined_df$Variable <- factor(combined_df$Variable, levels = levels(combined_df$Variable))  # keep order

p1 <- ggplot(combined_df, aes(x = Variable, y = `50%`, color = Significance_CI)) +
  geom_point(size = 3, color = "darkgray") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  scale_color_manual(values = c("Significant" = "black", "Not Significant" = "gray")) +
  labs(title = "Credible Interval", x = NULL, y = NULL) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.y = element_text(size = 8, hjust = 1),
    axis.text.x = element_text(size = 8),
    legend.position = "none"
  )

# --- Step 8: Save Plots ---
ggsave("Credible_interval_plot_OA2.pdf", plot = p1, width = 8, height = 6)
pdf("Credible_Interval_and_PIP_Plots_OA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2)
dev.off()

pdf("Credible_Interval_and_PIP_Plots_WidthOA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2, widths = c(0.65, 0.35))
dev.off()

# --- Step 9: Save Summary Table ---
write.csv(combined_df, "Predictor_Significance_and_PIP_Flexible.csv", row.names = FALSE)
pdf("Significance_and_PIP_Table_Flexible.pdf", width = 12, height = 8)
grid.table(combined_df)
dev.off()

# --- Optional: Print objects ---
print(p1)
print(p2)
head(combined_df)

```

```{r}


# Define Helper Function for Credible Intervals
calculate_quantiles <- function(beta_matrix, probs = c(0.025, 0.5, 0.975)) {
  apply(beta_matrix, 2, quantile, probs = probs)
}

# Calculate Credible Intervals from BETA_ZLV_thinned
beta_quantiles <- calculate_quantiles(BETA_ZLV_thinned)
beta_means <- colMeans(BETA_ZLV_thinned)
variable_names <- colnames(BETA_ZLV_thinned)  # Extract variable names dynamically

# Prepare Data for Plotting Credible Intervals
beta_df <- as.data.frame(t(beta_quantiles))
beta_df$Variable <- variable_names
beta_df <- beta_df[, c("Variable", "2.5%", "50%", "97.5%")]

# Identify Significant Predictors Based on Credible Intervals
significant_predictors <- variable_names[apply(beta_quantiles, 2, function(x) !(x[1] < 0 & x[3] > 0))]
beta_df$Significance <- ifelse(beta_df$Variable %in% significant_predictors, "Significant", "Not Significant")

# Exclude "Intercept" ONLY for Plotting
beta_df <- beta_df[beta_df$Variable != "(Intercept)", ]

p1 <- ggplot(beta_df, aes(x = reorder(Variable, `50%`), y = `50%`, color = Significance)) +
  geom_point(size = 3,color="red") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Credible Interval- Flexible Prior- Overall",
    x = "Predictors",
    y = "Posterior Mean"
  ) +
  scale_color_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10)
  )
ggsave("Credible_interval_plot_OA2.pdf", plot = p1, width = 8, height = 6)

# Calculate Posterior selection Probabilities (PIP) from ZLV_thinned
pip <- colMeans(ZLV_thinned)
pip_df <- data.frame(Variable = variable_names, PIP = pip)
pip_df$Significance <- ifelse(pip_df$Variable %in% significant_predictors, "Significant", "Not Significant")

# Exclude "Intercept" from PIP Data
pip_df <- pip_df[pip_df$Variable != "(Intercept)", ]

# Plot PIP Values
p2 <- ggplot(pip_df, aes(x = reorder(Variable, PIP), y = PIP, fill = Significance)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_fill_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  labs(
    title = "PIP- Flexible Prior- Overall",
    x = "Predictors",
    y = "PIP"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10)
  )

# Save Combined Plots as Side-by-Side
pdf("Credible_Interval_and_PIP_Plots_OA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2)
dev.off()

# Print Plots
print(p1)
print(p2)


```





```{r}
# Compute posterior mean and 95% credible interval for global θ
theta_mean <- mean(GLOBAL_THETA)
theta_ci <- quantile(GLOBAL_THETA, probs = c(0.025, 0.5, 0.975))

# Print results
cat("Posterior Mean of Global θ:", theta_mean, "\n")
cat("95% Credible Interval for Global θ:", theta_ci, "\n")

```


```{r}
# Convert GLOBAL_THETA samples to a dataframe for plotting
theta_df <- data.frame(GlobalTheta = GLOBAL_THETA)

# Plot posterior distribution of Global θ
p_theta <- ggplot(theta_df, aes(x = GlobalTheta)) +
  geom_density(fill = "blue", alpha = 0.5) +
  geom_vline(xintercept = theta_ci[1], linetype = "dashed", color = "red") +
  geom_vline(xintercept = theta_ci[3], linetype = "dashed", color = "red") +
  geom_vline(xintercept = theta_mean, linetype = "solid", color = "black") +
  labs(title = " ", x = "Global θ", y = "Density") +
  theme_minimal()

# Save the plot
ggsave("posterior_theta_distribution_OA2.pdf", plot = p_theta, width = 8, height = 6)

# Print the plot
print(p_theta)

```





```{r,eval=FALSE}
# Exclude "Intercept" from both beta_df and pip_df
beta_df <- beta_df[beta_df$Variable != "(Intercept)", ]
pip_df <- pip_df[pip_df$Variable != "(Intercept)", ]

# Create the PIP plot first to ensure the order is correct
p2 <- ggplot(pip_df, aes(x = reorder(Variable, PIP), y = PIP, fill = Significance)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_fill_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  labs(
    title = "PIP",
    x = "Predictors",
    y = "PIP"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10)
  )

# Extract the order of variables from the PIP plot
pip_order <- levels(reorder(pip_df$Variable, pip_df$PIP))

# Reorder the Variable column in beta_df to match the order in the PIP plot
beta_df$Variable <- factor(beta_df$Variable, levels = pip_order)

# Plot Credible Intervals with variables ordered by decreasing PIP values
p1 <- ggplot(beta_df, aes(x = Variable, y = `50%`, color = Significance)) +
  geom_point(size = 3, color = "darkgray") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Credible Interval",
    x = "Predictors",
    y = "Posterior Mean"
  ) +
  scale_color_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10)
  )

# Save the Credible Interval plot
ggsave("Credible_interval_plot_OA2.pdf", plot = p1, width = 8, height = 6)

# Save Combined Plots as Side-by-Side
pdf("Credible_Interval_and_PIP_Plots_OA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2)
dev.off()
pdf("Credible_Interval_and_PIP_Plots_widthOA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2, widths = c(0.65, 0.35))
dev.off()
# Print Plots
print(p1)
print(p2)
```


```{r}

pip <- colMeans(ZLV_thinned)
pip_df <- data.frame(Variable = variable_names, PIP = pip)
pip_df$Significance <- ifelse(pip_df$Variable %in% significant_predictors, "Significant", "Not Significant")

# Exclude "Intercept" from both beta_df and pip_df
beta_df <- beta_df[beta_df$Variable != "(Intercept)", ]
pip_df <- pip_df[pip_df$Variable != "(Intercept)", ]

# Create the PIP plot first to ensure the order is correct
p2 <- ggplot(pip_df, aes(x = reorder(Variable, PIP), y = PIP, fill = Significance)) +
  geom_bar(stat = "identity", width = 0.8) +
  scale_fill_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  labs(
    title = "Posterior selection probability",
    x = " ",
    y = " "
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
     axis.text.y = element_blank(),
    #axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.position = "none" # Remove legend
  )

# Extract the order of variables from the PIP plot
pip_order <- levels(reorder(pip_df$Variable, pip_df$PIP))

# Reorder the Variable column in beta_df to match the order in the PIP plot
beta_df$Variable <- factor(beta_df$Variable, levels = pip_order)

# Plot Credible Intervals with variables ordered by decreasing PIP values
p1 <- ggplot(beta_df, aes(x = Variable, y = `50%`, color = Significance)) +
  geom_point(size = 3, color = "darkgray") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Credible interval",
    x = " ",
    y = " "
  ) +
  scale_color_manual(
    values = c("Significant" = "black", "Not Significant" = "gray"),
    name = "Significance"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 14, face = "bold", color = "black"), # Larger, bolder text for y-axis labels
    axis.text.x = element_text(size = 12), # Adjust x-axis text size if needed
    legend.position = "none" # Remove legend
  )

# Save the Credible Interval plot
ggsave("Credible_interval_plot_OA2.pdf", plot = p1, width = 8, height = 6)

# Save Combined Plots as Side-by-Side
#pdf("Credible_Interval_and_PIP_Plots_OA2.pdf", width = 12, height = 8)
#grid.arrange(p1, p2, ncol = 2)
#dev.off()
pdf("Credible_Interval_and_PIP_Plots_width_OA2.pdf", width = 12, height = 8)
grid.arrange(p1, p2, ncol = 2, widths = c(0.65, 0.35))
dev.off()
# Print Plots
print(p1)
print(p2)
```

```{r}
significant_predictors
```



```{r}

# Load Required Libraries
library(ggplot2)
library(gridExtra)

# Define Helper Function for Credible Intervals
calculate_quantiles <- function(beta_matrix, probs = c(0.025, 0.5, 0.975)) {
  apply(beta_matrix, 2, quantile, probs = probs)
}

# Calculate Credible Intervals from BETA_ZLV_thinned
beta_quantiles <- calculate_quantiles(BETA_ZLV_thinned)
beta_means <- colMeans(BETA_ZLV_thinned)
variable_names <- colnames(BETA_ZLV_thinned)  # Extract variable names dynamically

# Prepare Data for Credible Intervals
beta_df <- as.data.frame(t(beta_quantiles))
beta_df$Variable <- variable_names
beta_df <- beta_df[, c("Variable", "2.5%", "50%", "97.5%")]

# Identify Significant Predictors Based on Credible Intervals
significant_predictors <- variable_names[apply(beta_quantiles, 2, function(x) !(x[1] < 0 & x[3] > 0))]
beta_df$Significance <- ifelse(beta_df$Variable %in% significant_predictors, "Significant", "Not-significant")

# Calculate Posterior selection Probabilities (PIP) from ZLV_thinned
pip <- colMeans(ZLV_thinned)
pip_df <- data.frame(Variable = variable_names, PIP_Flexible= pip)
pip_df$Significance <- ifelse(pip_df$Variable %in% significant_predictors, "Significant", "Not-significant")

# Combine Credible Intervals and PIP into a Single DataFrame
combined_df <- merge(beta_df, pip_df, by = "Variable", suffixes = c("_CI", "_PIP"))

# Compute Width of the 95% Credible Interval for Fixed Prior
combined_df$Width_Flexible <- combined_df$`97.5%` - combined_df$`2.5%`

# Select relevant columns
combined_df <- combined_df[, c("Variable", "2.5%", "50%", "97.5%", "Width_Flexible", "Significance_CI", "PIP_Flexible", "Significance_PIP")]

# Exclude "Intercept" from the Combined DataFrame
combined_df <- combined_df[combined_df$Variable != "(Intercept)", ]

# Print Combined DataFrame
print(combined_df)

# Save Combined DataFrame as CSV
write.csv(combined_df, "Predictor_Significance_and_PIP_Flexible.csv", row.names = FALSE)

# Visualize DataFrame as a Table
pdf("Significance_and_PIP_Table_Flexible.pdf", width = 12, height = 8)
grid.table(combined_df)
dev.off()
```

```{r}
# colmeans of beta_zlv thinned
beta_means
```


```{r}
colMeans(BETA_thinned) 

```
```{r}
# Evaluating the Model on Validation and Test Data 
predict_proba <- function(X, beta, zlv) {
  plogis(X %*% (beta * zlv))
}

beta_mean <- colMeans(BETA_thinned)
zlv_mean <- colMeans(ZLV_thinned)

train_preds <- predict_proba(X_train, beta_mean, zlv_mean)
#valid_preds <- predict_proba(X_valid, beta_mean, zlv_mean)
test_preds <- predict_proba(X_test, beta_mean, zlv_mean)

train_preds_binary <- ifelse(train_preds > 0.5, 1, 0)
#valid_preds_binary <- ifelse(valid_preds > 0.5, 1, 0)
test_preds_binary <- ifelse(test_preds > 0.5, 1, 0)

# Calculating Performance Metrics
calculate_metrics <- function(true_labels, pred_probs, pred_labels) {
  roc_curve <- roc(true_labels, pred_probs)
  auc <- auc(roc_curve)
  confusion <- confusionMatrix(factor(pred_labels), factor(true_labels))
  
  accuracy <- confusion$overall['Accuracy']
  f1 <- confusion$byClass['F1']
  sensitivity <- confusion$byClass['Sensitivity']
  specificity <- confusion$byClass['Specificity']
  precision <- confusion$byClass['Precision']
  error_rate <- 1 - accuracy
  fpr <- 1 - specificity
  fnr <- 1 - sensitivity
  tnr <- specificity
  
  list(
    Accuracy = accuracy,
    F1_Score = f1,
    Sensitivity = sensitivity,
    Specificity = specificity,
    Precision = precision,
    Error_Rate = error_rate,
    FPR = fpr,
    FNR = fnr,
    TNR = tnr,
    AUC = auc
  )
}

train_metrics <- calculate_metrics(y_train, train_preds, train_preds_binary)
#valid_metrics <- calculate_metrics(y_valid, valid_preds, valid_preds_binary)
test_metrics <- calculate_metrics(y_test, test_preds, test_preds_binary)

metrics_df <- data.frame(
  Metric = names(train_metrics),
  Train = unlist(train_metrics),
  #Validation = unlist(valid_metrics),
  Test = unlist(test_metrics)
)

pdf("performance_metrics_comparison_BVS_OA2.pdf", width = 8, height = 11)
grid.table(metrics_df)
dev.off()

```









```{r}
# Step 1: Compute log-likelihood at each MCMC iteration
loglik_samples <- numeric(nrow(BETA_thinned))
for (i in 1:nrow(BETA_thinned)) {
  loglik_samples[i] <- flogis.log(BETA_thinned[i, ], ZLV_thinned[i, ], X_train, y_train)
}
deviance_samples <- -2 * loglik_samples

# Step 2: Posterior mean deviance
D_bar <- mean(deviance_samples)

# Step 3: Compute deviance at posterior mean of (beta * Z)
# Note: this is the key correction — combining them first, then averaging
beta_zlv_mean <- colMeans(BETA_thinned * ZLV_thinned)

# Step 4: Evaluate deviance at this effective mean parameter vector
# Set Z vector to 1 because you've already zeroed out coefficients
D_hat <- -2 * flogis.log(beta_zlv_mean, rep(1, length(beta_zlv_mean)), X_train, y_train)

# Step 5: Effective number of parameters
p_D <- D_bar - D_hat

# Step 6: Compute DIC
DIC <- D_bar + p_D

# Step 7: Print result
cat("Posterior mean deviance (D̄):", round(D_bar, 2), "\n")
cat("Deviance at mean (D̂):", round(D_hat, 2), "\n")
cat("Effective number of parameters (pD):", round(p_D, 2), "\n")
cat("Deviance Information Criterion (DIC):", round(DIC, 2), "\n")

```



